{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[개념정리]\n",
        "================\n",
        "사이킷런\n",
        "- 파이썬 기반의 머신러닝을 위한 가장 쉽고 효율적인 개발 라이브러리를 제공\n",
        "\n",
        "지도학습\n",
        "- 학습을 위한 다양한 피처와 분류 결정값인 레이블 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측함\n",
        "- 명확한 정답이 주어진 데이터를 먼저 학습한 뒤 미지의 정답을 예측하는 방식\n",
        "- 학습 데이터 세트 / 테스트 데이터 세트 지칭\n",
        "- ex) 분류, 회귀\n",
        "\n",
        "train_test_split() : 학습 데이터와 테스트 데이터를 test_size 파라미터 입력 값의 비율로 쉽게 분할해냄\n",
        "shuffle : 데이터를 분리하기 전에 데이터를 미리 섞을지를 결정 / 디폴트는 True\n",
        "\n",
        "accuracy_score(실제,예측) : 정확도 측정\n",
        "\n",
        "분류를 예측한 프로세스\n",
        "1. 데이터 세트 분리 (train_test_split)\n",
        "2. 모델 학습        (fit)\n",
        "3. 예측 수행        (predict)\n",
        "4. 평가             (정확도)\n",
        "\n",
        "Estimator 클래스 : Classifier + Regressor\n",
        " (지도학습의 모든 알고리즘을 구현한 클래스)\n",
        "- Classifier : 분류 알고리즘 구현 클래스\n",
        "- Regressor : 회귀 알고리즘 구현 클래스\n",
        "\n",
        "내장된 데이터세트의 Key : data, target, target_name, feature_names, DESCR로 구성\n",
        "- data : 피처의 데이터 세트\n",
        "- target : 분류일 땐땐 레이블 값 / 회귀일 땐 결괏값 데이터 세트\n",
        "- target_names : 개별 레이블의 이름\n",
        "- feature_names : 피처의 이름\n",
        "- DESCR : 데이터 세트에 대한 설명, 각 피처의 설명\n",
        "\n",
        "과적합(overfitting) : 모델이 학습 데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 것 -> 교차검증으로 다양한 학습,평가 수행\n",
        "\n",
        "교차 검증 : 데이터 편증을 막기 위해서 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것\n",
        "\n",
        "학습 데이터 세트 -> 학습 데이터 세트 + 검증 데이터 세트(학습된 모델의 성능을 일차 평가함)\n",
        "\n",
        "K 폴드 교차 검증\n",
        "- K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법\n",
        "- 예측 평가 구한 후 평균해서 K폴드 평가 결과로 반영\n",
        "- 사이킷런에서 KFold, StratifiedKFold 클래스 제공\n",
        "1. 폴드 세트를 설정\n",
        "2. for 루프에서 반복으로 학습 및 테스트 데이터의 인덱스 추출\n",
        "3. 반복적으로 학습과 예측을 수행 + 예측 성능을 반환\n",
        "\n",
        "Stratified K 폴드\n",
        "- 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K폴드 방식\n",
        "- K 폴드가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 테스트 세트에 제대로 분배하지 못하는 경우의 문제를 해결해줌\n",
        "- 회귀에서는 지원 안됨\n",
        "  - 회귀의 결정값은 이산값 형태의 레이블이 아니라 연속된 숫자값이기 때문에 결정값별로 분포를 정하는 의미가 없기 때문\n",
        "\n",
        "cross_val_score() : 교차 검증을 보다 간편하게 ~\n",
        "- 반환 값은 scoring 파라미터로 지정된 성능 지표 측정값을 배열 형태로 반환\n",
        "- classifier가 입력되면 Stratified K폴드 방식으로 레이블값의 분포에 따라 학습/테스트 세트를 분할\n",
        "- cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n",
        "- estimator : Classifier / Regressor\n",
        "- X : 피처 데이터 세트\n",
        "- y : 레이블 데이터 세트\n",
        "- scoring : 예측 성능 평가 지표\n",
        "- cv : 교차 검증 폴드 수\n",
        "\n",
        "cross_validate() : 여러 개의 평가 지표 반환 가능한 ~\n",
        "\n",
        "GridSearchCV : 교차 검증, 하이퍼 파라미터 튜닝을 한 번에 ~\n",
        "- 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출할 수 있는 방안 제공함\n",
        "- 데이터 세트를 교차 검증을 위한 학습/테스트 세트로 자동 분할한 후에, 하이퍼 파라미터 그리드에 기술된 모든 파라미터를 순차적으로 적용해서 최적의 파라미터를 찾을 수 있게 해줌\n"
      ],
      "metadata": {
        "id": "MqyRNStnz4NF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsrI6BqJzl2i"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)    #사이킷런 버전 출력"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pg.89\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0nar0MoR0OIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pg.90\n",
        "import pandas as pd\n",
        "\n",
        "# 붓꽃 데이터 세트를 로딩합니다. \n",
        "iris = load_iris()\n",
        "\n",
        "# iris.data는 Iris 데이터 세트에서 피처(feature)만으로 된 데이터를 numpy로 가지고 있습니다. \n",
        "iris_data = iris.data\n",
        "\n",
        "# iris.target은 붓꽃 데이터 세트에서 레이블(결정 값) 데이터를 numpy로 가지고 있습니다. \n",
        "iris_label = iris.target\n",
        "print('iris target값:', iris_label)\n",
        "print('iris target명:', iris.target_names)\n",
        "\n",
        "# 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환합니다. \n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df.head(3)     # 레이블값(0,1,2) ///  0 : setosa품종  /  1 : versicolor품종  /  2 : virginica품종"
      ],
      "metadata": {
        "id": "QftoMGlV2jLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test_split() : 학습 데이터와 테스트 데이터를 test_size 파라미터 입력 값의 비율로 쉽게 분할해냄\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)\n",
        "# 전체 데이터 중 20%가 테스트 데이터 / 80%가 학습 데이터\n",
        "# iris_data : 피처 데이터 세트  /  iris_label : 레이블 데이터 세트  /  random_state : 호출할 때마다 같은 학습/테스트 용 데이터 세트를 생성하기 위해 주어지는 난수 발생 값"
      ],
      "metadata": {
        "id": "D43png_A3n61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DecisionTreeClassifier 객체 생성 \n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "\n",
        "# 학습 수행\n",
        "dt_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nAnsCjqu341A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행. \n",
        "pred = dt_clf.predict(X_test)   # 학습된 모델 기반에서 테스트 데이터 세트에 대한 예측값 반환"
      ],
      "metadata": {
        "id": "xBaJJ0p038K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도로 예측 성능 평가\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))   # accuracy_score(실제,예측) : 정확도 측정"
      ],
      "metadata": {
        "id": "SiRy4t6g6LiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pg.97\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "print(type(iris_data))"
      ],
      "metadata": {
        "id": "p7MADgep6ZBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = iris_data.keys()\n",
        "print('붓꽃 데이터 세트의 키들:', keys)"
      ],
      "metadata": {
        "id": "wqOPVGfG95bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n feature_names 의 type:',type(iris_data.feature_names))\n",
        "print(' feature_names 의 shape:',len(iris_data.feature_names))\n",
        "print(iris_data.feature_names)\n",
        "\n",
        "print('\\n target_names 의 type:',type(iris_data.target_names))\n",
        "print(' feature_names 의 shape:',len(iris_data.target_names))\n",
        "print(iris_data.target_names)\n",
        "\n",
        "print('\\n data 의 type:',type(iris_data.data))\n",
        "print(' data 의 shape:',iris_data.data.shape)\n",
        "print(iris_data['data'])\n",
        "\n",
        "print('\\n target 의 type:',type(iris_data.target))\n",
        "print(' target 의 shape:',iris_data.target.shape)\n",
        "print(iris_data.target)"
      ],
      "metadata": {
        "id": "zojrpEQQ-HEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pg.100\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "# 학습 데이터 세트로 예측 수행 -> 정확도가 100%\n",
        "pred = dt_clf.predict(train_data)\n",
        "print('예측 정확도:', accuracy_score(train_label,pred))"
      ],
      "metadata": {
        "id": "JpAowpGy-Nj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "iris_data = load_iris()\n",
        "\n",
        "# shuffle : 데이터를 분리하기 전에 데이터를 미리 섞을지를 결정 / 디폴트는 True\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
        "                                                    test_size = 0.3, random_state=121)"
      ],
      "metadata": {
        "id": "zu66_7YQSYG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터를 기반으로 DecisionTreeClassifier를 학습하고 모델을 이용해 예측 정확도를 측정\n",
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "id": "tLu255e1S1Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold   # KFold : k개의 폴드 세트로 분리해줌\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "# 5개의 폴드세트를 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터세트 크기: ', features.shape[0])"
      ],
      "metadata": {
        "id": "aBDB4bXkTLeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pg.103 : K 폴드 교차 검증\n",
        "\n",
        "n_iter = 0 \n",
        "\n",
        "# KFold 객체의 split() 을 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
        "for train_index, test_index in kfold.split(features):\n",
        "    # kfold.split() 으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 세트 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "\n",
        "    # 학습 및 예측\n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    pred = dt_clf.predict(X_test)\n",
        "    n_iter += 1\n",
        "    \n",
        "    # 반복 시 마다 정확도 측정\n",
        "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    \n",
        "    print('\\n{0} 교차검증 정확도 : {1}, 학습 데이터 크기 : {2}, 검증 데이터 크기 : {3}'.format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n",
        "    cv_accuracy.append(accuracy)\n",
        "    \n",
        "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
        "print('\\n## 평균검증 정확도: ', np.mean(cv_accuracy))"
      ],
      "metadata": {
        "id": "zeGhmlL-WTtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pg.106 : Stratified K 폴드\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label']  = iris.target\n",
        "iris_df['label'].value_counts()   # 레이블 값이 50개로 동일"
      ],
      "metadata": {
        "id": "ozJc29ZSXEYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "    n_iter+=1\n",
        "    label_train = iris_df['label'].iloc[train_index]\n",
        "    label_test = iris_df['label'].iloc[test_index]\n",
        "    print('\\n##교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포: \\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포: \\n', label_test.value_counts())\n",
        "    # 학습 레이블과 검증 레이블이 완전 다른 값 -> 예측 정확도 0"
      ],
      "metadata": {
        "id": "cYr38BY2YaZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "# 레이블 데이터 분포도에 따라 학습/검증 데이터를 나눔\n",
        "# -> split() 메서드에 인자로 피처 데이터 세트 뿐만 아니라 레이블 데이터 세트도 필요함\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "    n_iter += 1\n",
        "    label_train = iris_df['label'].iloc[train_index]\n",
        "    label_test = iris_df['label'].iloc[test_index]\n",
        "    print('\\n## 교차검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포: \\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포: \\n', label_test.value_counts())   # 모든 레이블 값에 분할되어 있음 -> 학습가능"
      ],
      "metadata": {
        "id": "_b7ogkmAYr7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 붓꽃 데이터 세트에서 Stratified Kfold 를 이용한 검증\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "cv_accuracy = []\n",
        "\n",
        "# StratifiedKFold의 split 호출 시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
        "for train_index, test_index in skfold.split(features, label):\n",
        "    #split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "\n",
        "    # 학습 및 예측\n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    pred = dt_clf.predict(X_test)\n",
        "\n",
        "    # 반복 시마다 정확도 측정\n",
        "    n_iter += 1\n",
        "    accuracy = np.round(accuracy_score(y_test, pred),4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    \n",
        "    print('{0} 교차검증 정확도: {1}, 학습데이터 크기: {2}, 검증데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
        "    cv_accuracy.append(accuracy)\n",
        "    \n",
        "# 교차검증별 정확도 및 평균정확도 계산\n",
        "print('\\n 교차검증별 정확도: ', cv_accuracy)\n",
        "print('## 평균 검증 정확도: ', np.mean(cv_accuracy))"
      ],
      "metadata": {
        "id": "y0WUbSD5bFbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pg.112 : cross_val_score()\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "# 교차검증 세트는 3개, 성능지표는 정확도(accuracy)\n",
        "scores = cross_val_score(dt_clf, data, label, cv =3 , scoring = 'accuracy')\n",
        "print('교차 검증별 정확도: ', np.round(scores, 4))\n",
        "print('평균 검증 정확도: ', np.round(np.mean(scores),4))"
      ],
      "metadata": {
        "id": "oFMxR-Qzb7Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pg.113 : GridSearchCV\n",
        "\n",
        "grid_parameters = {'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]}"
      ],
      "metadata": {
        "id": "L2cGmegofXFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터를 로딩하고 학습데이터와 테스트 데이터 분리\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.2, random_state=121)\n",
        "\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "## 파라미터를 딕셔너리 형태로 설정\n",
        "parameters = {'max_depth' : [1, 2, 3], 'min_samples_split' : [2, 3]}"
      ],
      "metadata": {
        "id": "xjy2uMP7gE9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 데이터 세트를 GridSearchCV 객체의 fit 메서드에 인자로 입력\n",
        "\n",
        "-> 학습데이터를 cv에 입력된 폴딩 수로 분할\n",
        "\n",
        "-> param_grid에 기술된 하이퍼파라미터로 순차적으로 변경하며 학습/평가 수행\n",
        "\n",
        "-> 개별 평가결과 : cv_results_ 에 기록\n",
        "\n",
        "-> 최고 성능 파라미터 : best_params_ 에 기록\n",
        "\n",
        "-> 최고 점수 : best_score_ 에 기록"
      ],
      "metadata": {
        "id": "qQRWaBdwiz4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# param_grid의  하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정\n",
        "### refit=True가 기본 설정으로 True이면 가장 좋은 파라미터 설정으로 재학습 시킴\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
        "\n",
        "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습, 평가\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "# GridSearchCV 결과를 추출해 데이터 프레임으로 반환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "metadata": {
        "id": "t3sdv4FthWBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- params : 적용된 개별 하이퍼 파라미터 값\n",
        "- rank_test_score : 성능이 좋게 나온 score 순위 (1이 가장 뛰어남 -> 최적의 하이퍼 파라미터)\n",
        "- mean_test_score : 개별 하이퍼파라미터별로 CV 폴딩 테스트의 평가 평균 값"
      ],
      "metadata": {
        "id": "PVO2By1kigOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('GridSearch 최적 파라미터: ', grid_dtree.best_params_)\n",
        "print('GridSearch 최고 점수: ', grid_dtree.best_score_)"
      ],
      "metadata": {
        "id": "iuN_ClOChpqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV의 refit으로 학습된 estimator 반환\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "# GridSearchCV의 best_estmator_ 는 이미 최적 학습이 됐으므로 별도 학습이 필요 없음\n",
        "pred = estimator.predict(X_test)\n",
        "print('테스트 데이터세트 정확도: {0: .4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "id": "cUxMkr3Jh_ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2AXXJ1u_iBRB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}